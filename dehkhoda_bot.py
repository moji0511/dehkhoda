# dehkhoda_bot.py
import os
import logging
import re
import html
from urllib.parse import quote_plus

import requests
from bs4 import BeautifulSoup
from telegram import ParseMode
from telegram.ext import Updater, MessageHandler, Filters, CommandHandler

# ====== ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§Ø² Ù…Ø­ÛŒØ· ======
TOKEN = os.environ.get("TELEGRAM_TOKEN")
if not TOKEN:
    raise SystemExit("ERROR: TELEGRAM_TOKEN environment variable is not set")

GROUP_TAG = os.environ.get("GROUP_TAG", "@iran9897")
USER_AGENT = os.environ.get("USER_AGENT", "Mozilla/5.0 (compatible)")

# ====== Ù„Ø§Ú¯ ======
logging.basicConfig(format='%(asctime)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

def _looks_like_persian_meaning(text: str) -> bool:
    return bool(re.search(r'[\u0600-\u06FF]', text)) and len(text) > 10

def search_dehkhoda(word: str) -> str:
    word = (word or "").strip()
    if not word:
        return "Ú©Ù„Ù…Ù‡â€ŒØ§ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ Ø¯Ø§Ø¯Ù‡ Ù†Ø´Ø¯Ù‡."

    headers = {"User-Agent": USER_AGENT}
    urls = [
        f"https://www.vajehyab.com/dehkhoda/{quote_plus(word)}",
        f"https://www.vajehyab.com/?q={quote_plus(word)}&pv=dehkhoda",
        f"https://www.loghatnameh.org/{quote_plus(word)}",
    ]

    candidates = []
    for url in urls:
        try:
            r = requests.get(url, headers=headers, timeout=8)
            if r.status_code != 200:
                continue
            soup = BeautifulSoup(r.text, "html.parser")
            # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø§Ù„Ù…Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ Ù…Ø¹Ù†ÛŒ
            for sel in ['div.meaning', 'div.mean', 'div.definition', 'div.entry', 'div#content', 'article']:
                el = soup.select_one(sel)
                if el:
                    text = el.get_text("\n", strip=True)
                    if _looks_like_persian_meaning(text):
                        candidates.append(text)
            # Ø§Ú¯Ø± Ú†ÛŒØ²ÛŒ Ù†ÛŒÙˆÙ…Ø¯ Ù¾Ø§Ø±Ø§Ú¯Ø±Ø§ÙÙ‡Ø§ÛŒ Ù…Ø¹Ù‚ÙˆÙ„ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†
            for p in soup.find_all(['p', 'div', 'span']):
                t = p.get_text(" ", strip=True)
                if _looks_like_persian_meaning(t):
                    candidates.append(t)
            if candidates:
                # Ø¨Ù„Ù†Ø¯ØªØ±ÛŒÙ† Ù†ØªÛŒØ¬Ù‡ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†
                candidates = sorted(set(candidates), key=lambda s: len(s), reverse=True)
                return candidates[0][:3000]
        except Exception as e:
            logger.debug("scrape error %s: %s", url, e)
            continue

    return "Ù…Ø¹Ù†ÛŒâ€ŒØ§ÛŒ Ø¯Ø± Ù…Ù†Ø§Ø¨Ø¹ Ù‚Ø§Ø¨Ù„â€ŒØ¯Ø³ØªØ±Ø³ÛŒ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯."

def start(update, context):
    update.message.reply_text(
        "Ø±Ø¨Ø§Øª Ø¯Ù‡Ø®Ø¯Ø§ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Øª.\nØ±ÙˆØ´ Ø§Ø³ØªÙØ§Ø¯Ù‡:\nâ€” Ø±ÙˆÛŒ Ù¾ÛŒØ§Ù…Ù Ú©Ù„Ù…Ù‡ (Ù…Ø«Ù„Ø§Ù‹ `Ø¢Ø³Ù…Ø§Ù†`) Ø±ÛŒÙ¾Ù„Ø§ÛŒ Ú©Ù† Ùˆ ÙÙ‚Ø· Ø¨Ù†ÙˆÛŒØ³ `Ø¯Ù‡Ø®Ø¯Ø§`.\nâ€” ÛŒØ§ ØªØ§ÛŒÙ¾ Ú©Ù† `Ø¯Ù‡Ø®Ø¯Ø§ Ú©Ù„Ù…Ù‡`"
    )

def handle_message(update, context):
    msg = update.message
    if not msg:
        return
    text = (msg.text or "").strip()
    trigger = "Ø¯Ù‡Ø®Ø¯Ø§"

    # Ø­Ø§Ù„Øª Ø±ÛŒÙ¾Ù„Ø§ÛŒ + ÙÙ‚Ø· 'Ø¯Ù‡Ø®Ø¯Ø§' ÛŒØ§ 'Ø¯Ù‡Ø®Ø¯Ø§ <Ú©Ù„Ù…Ù‡>'
    if msg.reply_to_message and trigger in text:
        after = text.split(trigger, 1)[1].strip()
        if after:
            query = after.splitlines()[0].strip()
        else:
            # Ø§Ø² Ù…ØªÙ† Ù¾ÛŒØ§Ù…Ù Ø±ÛŒÙ¾Ù„Ø§ÛŒâ€ŒØ´Ø¯Ù‡ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ú©Ù†
            query = (msg.reply_to_message.text or msg.reply_to_message.caption or "").strip()
            if not query:
                msg.reply_text("Ù„Ø·ÙØ§Ù‹ Ø±ÙˆÛŒ ÛŒÚ© Ù¾ÛŒØ§Ù… Ù…ØªÙ†ÛŒ Ø±ÛŒÙ¾Ù„Ø§ÛŒ Ú©Ù† (Ù…Ø«Ù„Ø§Ù‹ `Ø¢Ø³Ù…Ø§Ù†`).")
                return
        if len(query.split()) > 6:
            query = query.split()[0]
        meaning = search_dehkhoda(query)
        out = f"ğŸ” Ù…Ø¹Ù†ÛŒ Â«{html.escape(query)}Â» Ø¯Ø± Ù„ØºØªâ€ŒÙ†Ø§Ù…Ù‡Ù” Ø¯Ù‡Ø®Ø¯Ø§:\n\n{html.escape(meaning)}\n\nÚ¯Ø±ÙˆÙ‡ Ø¨Ú†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±ÙˆÙ† {GROUP_TAG}"
        try:
            msg.reply_to_message.reply_text(out, parse_mode=ParseMode.HTML)
        except Exception:
            msg.reply_text(out, parse_mode=ParseMode.HTML)
        return

    # Ø­Ø§Ù„Øª Ø¨Ø¯ÙˆÙ† Ø±ÛŒÙ¾Ù„Ø§ÛŒ: 'Ø¯Ù‡Ø®Ø¯Ø§ Ú©Ù„Ù…Ù‡'
    if text.startswith(trigger):
        after = text[len(trigger):].strip()
        if not after:
            msg.reply_text("Ø¨Ø±Ø§ÛŒ Ø§Ø³ØªÙØ§Ø¯Ù‡: Ø±ÙˆÛŒ Ù¾ÛŒØ§Ù… Ú©Ù„Ù…Ù‡ Ø±ÛŒÙ¾Ù„Ø§ÛŒ Ú©Ù† Ùˆ `Ø¯Ù‡Ø®Ø¯Ø§` Ø¨Ù†ÙˆÛŒØ³ØŒ ÛŒØ§ `Ø¯Ù‡Ø®Ø¯Ø§ Ú©Ù„Ù…Ù‡` Ø¨Ù†ÙˆÛŒØ³.")
            return
        query = after.split()[0]
        meaning = search_dehkhoda(query)
        out = f"ğŸ” Ù…Ø¹Ù†ÛŒ Â«{html.escape(query)}Â» Ø¯Ø± Ù„ØºØªâ€ŒÙ†Ø§Ù…Ù‡Ù” Ø¯Ù‡Ø®Ø¯Ø§:\n\n{html.escape(meaning)}\n\nÚ¯Ø±ÙˆÙ‡ Ø¨Ú†Ù‡â€ŒÙ‡Ø§ÛŒ Ø§ÛŒØ±ÙˆÙ† {GROUP_TAG}"
        msg.reply_text(out, parse_mode=ParseMode.HTML)
        return

def main():
    updater = Updater(TOKEN, use_context=True)
    dp = updater.dispatcher
    dp.add_handler(CommandHandler("start", start))
    dp.add_handler(MessageHandler(Filters.text & (~Filters.command), handle_message))
    logger.info("Bot is starting...")
    updater.start_polling()
    updater.idle()

if __name__ == "__main__":
    main()
